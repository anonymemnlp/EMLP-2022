{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312558ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb7465-befd-4e39-b4cc-6353c9ba9f20",
   "metadata": {},
   "source": [
    "### Change device for GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eaa8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "for index in range(n_gpu):\n",
    "    print(torch.cuda.get_device_name(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd03649",
   "metadata": {},
   "source": [
    "## Load Data (Dataframes / Dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6138942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train.csv') \n",
    "df = df[df.columns[3:]]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc660c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('../dev.csv')\n",
    "df_dev = df_dev[df_dev.columns[3:]]\n",
    "print(df_dev.shape)\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f022179-4ef1-44c4-b9b7-b52bf4f8898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('../test.csv')\n",
    "df_dev = df_dev[df_dev.columns[3:]]\n",
    "print(df_dev.shape)\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d36905",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = df.columns.to_list()\n",
    "num_labels = len(label_cols)\n",
    "bs = 8\n",
    "max_length = 512\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_prefix = \"\"\n",
    "train_dataloader = torch.load(f'dataloaders/{small_prefix}train_data_loader-{bs}-{max_length}')\n",
    "validation_dataloader = torch.load(f'dataloaders/validation_data_loader-{bs}-{max_length}')\n",
    "test_dataloader = torch.load(f'dataloaders/test_data_loader-{bs}-{max_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3fb90",
   "metadata": {},
   "source": [
    "## Target Probabilities Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9820c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.astype(bool).sum(axis=0).to_dict()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dev = df_dev.astype(bool).sum(axis=0).to_dict()\n",
    "print(counts_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dab148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_target_prob_tensor(counts: dict, dataframe):\n",
    "    columns = list(counts.keys())\n",
    "    target_prob = []\n",
    "    for column_1 in tqdm(columns, desc=\"Column-1\", leave=True):\n",
    "        temp_list = []\n",
    "        for column_2 in tqdm(columns, desc=\"Column-2\", leave=False):\n",
    "\n",
    "            count = len(dataframe[(dataframe[column_1] == 1) & (dataframe[column_2] == 1)])\n",
    "            freq = count / counts[column_1] if counts[column_1] else 0\n",
    "            temp_list.append(freq)\n",
    "            \n",
    "        target_prob.append(temp_list)\n",
    "        \n",
    "    target_prob = torch.tensor(target_prob, dtype=torch.float32)\n",
    "    target_prob = target_prob # - 0.5\n",
    "    return target_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83391360",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_probs = make_target_prob_tensor(counts=counts, dataframe=df)\n",
    "target_probs = target_probs.to(device)\n",
    "print(target_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a9cfa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_probs_dev = make_target_prob_tensor(counts=counts_dev, dataframe=df_dev)\n",
    "target_probs_dev = target_probs_dev.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'dev': validation_dataloader,\n",
    "    'test': test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca52b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_probabs = {\n",
    "    'train': target_probs,\n",
    "    'dev': target_probs_dev\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9066b3",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1468a5",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(method, f1, acc, precision, recall):\n",
    "    print('\\n'+method+' :')\n",
    "    print('Micro F1-Score =', f1)\n",
    "    print('Accuracy =', acc)\n",
    "    print('Micro Avg : precision =', precision, 'recall =', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(method, f1, acc, precision, recall):\n",
    "    print('\\n'+method+' :')\n",
    "    print('Micro F1-Score =', f1)\n",
    "    print('Accuracy =', acc)\n",
    "    print('Micro Avg : precision =', precision, 'recall =', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_bools, pred_bools):\n",
    "    clf_report_optimized = classification_report(true_bools, pred_bools, target_names=label_cols, digits=5, zero_division=0, output_dict=True)\n",
    "    micro_avg = clf_report_optimized['micro avg']\n",
    "    f1 = f1_score(true_bools, pred_bools,average='micro')*100\n",
    "    acc = accuracy_score(true_bools, pred_bools)*100\n",
    "    precision = micro_avg['precision']*100\n",
    "    recall = micro_avg['recall']*100\n",
    "    \n",
    "    return f1, acc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429d2e4",
   "metadata": {},
   "source": [
    "### Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c41f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=num_labels)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce1ad6-cf85-417c-a20a-f076f8b8d78a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class DepClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, out_features, weight_tensor):\n",
    "        super(DepClassifier, self).__init__()\n",
    "        self.weight_tensor = weight_tensor\n",
    "        self.dense = torch.nn.Linear(in_features=input_size, out_features=out_features, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.dense(x)\n",
    "        \n",
    "        #  activation with label frequencies\n",
    "        bs = out.shape[0]\n",
    "        d_labels = out.shape[1] \n",
    "        out = torch.reshape(out, (bs, 1, d_labels))\n",
    "        out = torch.bmm(out, torch.broadcast_to(self.weight_tensor, (bs, d_labels, d_labels)))\n",
    "        out = torch.squeeze(out, dim=1)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d099e-a5c3-4742-b4d6-a6abacfea0cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.classifier = DepClassifier(input_size=768, out_features=num_labels, weight_tensor=target_probabs['train'])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ea566",
   "metadata": {},
   "source": [
    "### Loss function and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4b8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "# single = ['dense_2', 'pooler']\n",
    "\n",
    "\n",
    "#exclude the last layer parameter from optimizer\n",
    "optimizer_grouped_parameters_classification = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)] ,\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_classification = torch.optim.AdamW(optimizer_grouped_parameters_classification, lr=2e-5)\n",
    "\n",
    "classification_criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52694a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Heatmap visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715eacd1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def get_heatmap(input_tensor):\n",
    "    input_tensor = input_tensor.cpu().detach()\n",
    "    input_tensor = input_tensor.tolist()\n",
    "    input_tensor_dict = dict()\n",
    "    \n",
    "    for index_1, column_1 in enumerate(tqdm(label_cols, desc=\"Labels\", leave=False)):\n",
    "        input_tensor_dict[column_1] = dict()\n",
    "        for index_2, column_2 in enumerate(tqdm(label_cols, desc=\"Column-2\", leave=False)):       \n",
    "            input_tensor_dict[column_1][column_2] = input_tensor[index_1][index_2]\n",
    "            \n",
    "    input_tensor_df = pd.DataFrame.from_dict(input_tensor_dict)\n",
    "    f, ax = plt.subplots(figsize=(40, 30))\n",
    "    heatmap = sns.heatmap(input_tensor_df, annot=True, fmt=\".2f\", linewidths=2, ax=ax)\n",
    "\n",
    "    img_buf = io.BytesIO()\n",
    "    heatmap.get_figure().savefig(img_buf, format='png')\n",
    "    plt.close()\n",
    "    heatmap_image = Image.open(img_buf)\n",
    "\n",
    "    return heatmap_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b576f41",
   "metadata": {},
   "source": [
    "### Logging and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"your_model_name\"\n",
    "dataset_name = \"dataset_name\"\n",
    "epochs = 30 # Number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "config = {\"epochs\": epochs, \"batch_size\": bs, \"seq_max_length\": max_length,\n",
    "          \"lr_cls\": 2e-5,\n",
    "         \"optimizer\": \"AdamW\", \"wd\": 0.01}\n",
    "config.update({\"dataset\": dataset_name})\n",
    "\n",
    "# mode = \"disabled\"\n",
    "wandb.init(project=\"project_name\", entity=\"your_entity\", name=\"run_name\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_set = np.array([])\n",
    "train_classif_loss = np.array([])\n",
    "train_dependency_loss = np.array([])\n",
    "all_val_f1s = np.array([])\n",
    "all_val_accs = np.array([])\n",
    "all_val_precisions = np.array([])\n",
    "all_val_recalls = np.array([])\n",
    "\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_val_f1 = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad82b1",
   "metadata": {},
   "source": [
    "### Train !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6977ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "model.eval()\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for epoch_num in trange(epochs, desc=\"Epoch\", position=0):\n",
    "    \n",
    "    for phase in tqdm(['train', 'dev', 'test'], leave=False, desc='Phases', position=1):\n",
    "\n",
    "        # Tracking variables\n",
    "        true_labels,pred_labels = [], [] # for metrics\n",
    "        epoch_loss, cls_loss = 0, 0 #running losses\n",
    "        epoch_steps = 0\n",
    "        \n",
    "        if phase == 'train': \n",
    "            model.train()\n",
    "            \n",
    "        if phase == 'dev':\n",
    "            model.eval()\n",
    "            \n",
    "        for step, batch in enumerate(tqdm(dataloaders[phase], leave=False, desc=f\"{phase.capitalize()} Dataloader\", position=2)):\n",
    "\n",
    "            # Add batch to GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Unpack the inputs from our dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # Forward pass for multilabel classification\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(b_input_ids, attention_mask=b_input_mask)[0]\n",
    "                classification_logits = outputs\n",
    "                \n",
    "            del b_input_ids, b_input_mask, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            #loss calculation\n",
    "            loss = classification_criterion(classification_logits, b_labels.type_as(classification_logits))\n",
    "            \n",
    "            if phase == 'train': \n",
    "\n",
    "                # Clear out the gradients \n",
    "                optimizer_classification.zero_grad()\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                    \n",
    "                # Update parameters and take a step using the computed gradient\n",
    "                optimizer_classification.step()\n",
    "\n",
    "            # Update tracking variables\n",
    "            cls_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            \n",
    "            # Update Epoch Metrics\n",
    "            pred_label = classification_logits.detach().to('cpu').numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "            \n",
    "\n",
    "\n",
    "        # Get Epoch Metrics\n",
    "        # Flatten outputs\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "        \n",
    "        true_bools = true_labels \n",
    "        pred_bools = [pl>threshold for pl in pred_labels] \n",
    "        f1_accuracy, flat_accuracy, precision, recall = get_metrics(true_bools, pred_bools)\n",
    "        \n",
    "        # Get Epoch Losses\n",
    "        cls_loss = cls_loss/epoch_steps\n",
    "\n",
    "        # Log Epoch Metrics\n",
    "        metrics = {\n",
    "            'F1_score': f1_accuracy,\n",
    "            'Accuracy': flat_accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'Cls_loss': cls_loss,\n",
    "        }\n",
    "        wandb.log({f'{phase.capitalize()}': metrics}, commit=False)\n",
    "        \n",
    "        # Save model if valid performances are better\n",
    "        if phase == 'dev':\n",
    "            if  f1_accuracy > best_val_f1:\n",
    "                best_val_f1 = f1_accuracy\n",
    "                torch.save(model.state_dict(), 'state_dicts/best_'+ model_name +'.pt')\n",
    "\n",
    "\n",
    "    wandb.log(data={}, commit=True)\n",
    "        \n",
    "    \n",
    "# save last model\n",
    "torch.save(model.state_dict(), 'state_dicts/last_'+ model_name +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22da1c-4089-448e-abb2-b9a325d2f1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
